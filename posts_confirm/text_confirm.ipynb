{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La réponse correspond à la mission : Prendre une photo de vous avec @product\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Missions à remplir\n",
    "missions = [\n",
    "    \"Faire un post pour présenter @product\",\n",
    "    \"Faire une story à propos de @product\",\n",
    "    \"Prendre une photo de vous avec @product\"\n",
    "]\n",
    "\n",
    "# Réponse à vérifier\n",
    "response = \"J'ai acheté @product hier et je suis très satisfait de mon achat. J'ai publié une photo avec @product sur Instagram et j'ai partagé une story à propos de mon expérience avec @product.\"\n",
    "\n",
    "# Expression régulière pour extraire les tags et les mentions\n",
    "pattern = r\"(#\\w+)|(@\\w+)\"\n",
    "\n",
    "# Extraire les tags et les mentions de la réponse\n",
    "response_tags_mentions = set(re.findall(pattern, response))\n",
    "\n",
    "# Extraire le texte de la réponse\n",
    "response_text = re.sub(pattern, \"\", response).strip()\n",
    "\n",
    "# Vectoriser le texte des missions et de la réponse\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "mission_vectors = vectorizer.fit_transform(missions)\n",
    "response_vector = vectorizer.transform([response_text])\n",
    "\n",
    "# Entraîner un modèle de classification logistique pour prédire la mission appropriée\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(mission_vectors, np.arange(len(missions)))\n",
    "prediction = clf.predict(response_vector)[0]\n",
    "\n",
    "# Afficher la mission prédite\n",
    "print(f\"La réponse correspond à la mission : {missions[prediction]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chams\\AppData\\Local\\Temp\\ipykernel_20112\\3725405068.py:78: RuntimeWarning: invalid value encountered in divide\n",
      "  similarity = np.dot(mission_vector, response_vector.T) / (np.linalg.norm(mission_vector) * np.linalg.norm( response_vector.T))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from torch import cosine_similarity\n",
    "import torch\n",
    "from Twitterpreprocessor import TwitterPreprocessor\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "missions = [\n",
    "\"Write a positive sentence about SaTT\",\n",
    "\"Include #SaTT #crypto #influencer #Post2Earn #SocialFi \",\n",
    "\"Include “Earn crypto with your social networks” in your post \"\n",
    "]\n",
    "\n",
    "response = \" \"\n",
    "def porterstemmer(text):\n",
    "  text = ' '.join(ps.stem(word) for word in text.split() if word in text)\n",
    "  return text  \n",
    "\n",
    "def lemmatization (text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(tokens)\n",
    "def encode_text(text):\n",
    "        # clean text from stop wods and punctuation\n",
    "        text=TwitterPreprocessor(str(text)).fully_preprocess().text\n",
    "        text=porterstemmer(text)\n",
    "        text=lemmatization(text)\n",
    "        text =[text]\n",
    "        vectorizer = joblib.load('vectorizer.pkl')\n",
    "        text = vectorizer.transform(text)\n",
    "        text = torch.tensor(text.toarray())\n",
    "        return text\n",
    "def text_confirm(missions,response):\n",
    "    # Expression régulière pour extraire les tags et les mentions\n",
    "    pattern = r\"([@#]\\w+)\"\n",
    "    lien_pattern= re.compile(\n",
    "            r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))'\n",
    "            r'[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})')\n",
    "    # Extraire les tags et les mentions de la réponse\n",
    "    response_tags_mentions = set(re.findall(pattern, response))\n",
    "    response_lien = set(re.findall(lien_pattern, response))\n",
    "    # Extraire le texte de la réponse\n",
    "    response_text = re.sub(pattern, \"\", response).strip()\n",
    "    response_text = re.sub(lien_pattern, \"\", response_text).strip()\n",
    "    # Initialiser le score de validation à 0\n",
    "    validation_score = 0\n",
    "    total=0\n",
    "    # Vérifier chaque mission\n",
    "    for mission in missions:\n",
    "        # Extraire les tags et les mentions de la mission\n",
    "        mission_tags_mentions = set(re.findall(pattern, mission))\n",
    "        total+=len(mission_tags_mentions)\n",
    "    \n",
    "        mission_lien = set(re.findall(lien_pattern, mission))\n",
    "        total+=len(mission_lien)\n",
    "    \n",
    "        # Vérifier si tous les tags et mentions de la mission sont présents dans la réponse\n",
    "        validation_score +=len(mission_tags_mentions.intersection(response_tags_mentions))\n",
    "        validation_score +=len(mission_lien.intersection(response_lien))\n",
    "        mission_text = re.sub(pattern,\"\", mission).strip()\n",
    "        mission_text = re.sub(lien_pattern,\"\", mission).strip()\n",
    "        mission_vector = encode_text(mission_text)\n",
    "        response_vector = encode_text(response_text)\n",
    "        # Print the shapes\n",
    "        \n",
    "        mission_vector = mission_vector.float()\n",
    "        response_vector = response_vector.float()\n",
    "  \n",
    "        # Calcul de la similarité cosinus\n",
    "        # similarity = cosine_similarity(mission_vector, response_vector)[0][0]\n",
    "        similarity = np.dot(mission_vector, response_vector.T) / (np.linalg.norm(mission_vector) * np.linalg.norm( response_vector.T))\n",
    "        total+=2\n",
    "        if similarity > 0.7:\n",
    "            # Ajouter un point si la similarité est suffisante\n",
    "            validation_score += 1\n",
    "    clf = joblib.load('postclf.pkl')\n",
    "    predicted=clf.predict(response_vector)\n",
    "    \n",
    "    validation_score += 1 if predicted[0] == 1 else 0\n",
    "    # Afficher le score de validation\n",
    "    return round(validation_score *5 / total)\n",
    "print(text_confirm(missions,response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tester avec chatgbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" 4/5\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1684158984,\n",
      "  \"id\": \"cmpl-7GSyWKZ6gfiG4ysiZcFBwuiADKEgj\",\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 3,\n",
      "    \"prompt_tokens\": 129,\n",
      "    \"total_tokens\": 132\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import tweepy\n",
    "from decouple import config\n",
    "\n",
    "oracle=0\n",
    "id_poste=0\n",
    "def get_poste(oracle,id_poste):\n",
    "    desc=\"\"\n",
    "    if oracle == 0:\n",
    "        consumer_key = config('TWITTER_CONSUMER_KEY')\n",
    "        consumer_secret = config('TWITTER_CONSUMER_SECRET')\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        # auth.set_access_token(access_key,access_secret)\n",
    "        api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "    elif oracle == 1:\n",
    "        oracle=0\n",
    "    return desc   \n",
    "\n",
    "\n",
    "    \n",
    "def text_confirm():\n",
    "  mission=[]\n",
    "  poste=get_poste(oracle,id_poste)\n",
    "  openai.api_key = config('OpenAI')\n",
    "  start_sequence = \"\\nA:\"\n",
    "  restart_sequence = \"\\n\\nQ: \"\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Q:donnes un score sur 5  pour la confirmiter de ce poste a ces mission :\\nposte: {poste} \\n mission:{mission}\\nA:\",\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=[\"\\n\"]\n",
    "  )\n",
    "  response = list(response)\n",
    "  return response[\"choices\"][0][\"text\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

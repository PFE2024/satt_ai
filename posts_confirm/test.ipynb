{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La réponse correspond à la mission : Prendre une photo de vous avec @product\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Missions à remplir\n",
    "missions = [\n",
    "    \"Faire un post pour présenter @product\",\n",
    "    \"Faire une story à propos de @product\",\n",
    "    \"Prendre une photo de vous avec @product\"\n",
    "]\n",
    "\n",
    "# Réponse à vérifier\n",
    "response = \"J'ai acheté @product hier et je suis très satisfait de mon achat. J'ai publié une photo avec @product sur Instagram et j'ai partagé une story à propos de mon expérience avec @product.\"\n",
    "\n",
    "# Expression régulière pour extraire les tags et les mentions\n",
    "pattern = r\"(#\\w+)|(@\\w+)\"\n",
    "\n",
    "# Extraire les tags et les mentions de la réponse\n",
    "response_tags_mentions = set(re.findall(pattern, response))\n",
    "\n",
    "# Extraire le texte de la réponse\n",
    "response_text = re.sub(pattern, \"\", response).strip()\n",
    "\n",
    "# Vectoriser le texte des missions et de la réponse\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "mission_vectors = vectorizer.fit_transform(missions)\n",
    "response_vector = vectorizer.transform([response_text])\n",
    "\n",
    "# Entraîner un modèle de classification logistique pour prédire la mission appropriée\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "clf.fit(mission_vectors, np.arange(len(missions)))\n",
    "prediction = clf.predict(response_vector)[0]\n",
    "\n",
    "# Afficher la mission prédite\n",
    "print(f\"La réponse correspond à la mission : {missions[prediction]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faire un post pour présenter\n",
      "J'ai acheté  hier et je suis très satisfait de mon achat. J'ai publié une photo avec  sur Instagram et j'ai partagé une story à propos de mon expérience avec .\n",
      "Faire une story à propos de\n",
      "J'ai acheté  hier et je suis très satisfait de mon achat. J'ai publié une photo avec  sur Instagram et j'ai partagé une story à propos de mon expérience avec .\n",
      "Prendre une photo de vous avec\n",
      "J'ai acheté  hier et je suis très satisfait de mon achat. J'ai publié une photo avec  sur Instagram et j'ai partagé une story à propos de mon expérience avec .\n",
      "Le score de validation pour la réponse est : 3/6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Missions à remplir\n",
    "missions = [\n",
    "    \"Faire un post pour présenter @product\",\n",
    "    \"Faire une story à propos de @product\",\n",
    "    \"Prendre une photo de vous avec @product\"\n",
    "]\n",
    "\n",
    "# Réponse à vérifier\n",
    "response = \"J'ai acheté @product hier et je suis très satisfait de mon achat. J'ai publié une photo avec @product sur Instagram et j'ai partagé une story à propos de mon expérience avec @product.\"\n",
    "\n",
    "# Expression régulière pour extraire les tags et les mentions\n",
    "pattern = r\"(#\\w+)|(@\\w+)\"\n",
    "\n",
    "# Extraire les tags et les mentions de la réponse\n",
    "response_tags_mentions = set(re.findall(pattern, response))\n",
    "\n",
    "# Extraire le texte de la réponse\n",
    "response_text = re.sub(pattern, \"\", response).strip()\n",
    "\n",
    "# Initialiser le score de validation à 0\n",
    "validation_score = 0\n",
    "\n",
    "# Vérifier chaque mission\n",
    "for mission in missions:\n",
    "    # Extraire les tags et les mentions de la mission\n",
    "    mission_tags_mentions = set(re.findall(pattern, mission))\n",
    "    # Vérifier si tous les tags et mentions de la mission sont présents dans la réponse\n",
    "    if mission_tags_mentions.issubset(response_tags_mentions):\n",
    "        # Ajouter un point si tous les tags et mentions sont présents\n",
    "        validation_score += 1\n",
    "    # Vérifier si le texte de la mission est présent dans la réponse\n",
    "    if mission_text := re.sub(pattern, \"\", mission).strip():\n",
    "        print(mission_text)\n",
    "        print(response_text)\n",
    "        if mission_text in response_text:\n",
    "            print(\"in\")\n",
    "            # Ajouter un point si le texte de la mission est présent\n",
    "            validation_score += 1\n",
    "\n",
    "# Afficher le score de validation\n",
    "print(f\"Le score de validation pour la réponse est : {validation_score}/{len(missions)*2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dsi\\PFE\\AI\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score de validation pour la réponse est : 6/6\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "# twitter \n",
    "# Missions à remplir\n",
    "\n",
    "# emojies + lien \n",
    "\n",
    "missions = [\n",
    "\"Write a positive sentence about SaTT\",\n",
    "\"Include #SaTT #crypto #influencer #Post2Earn #SocialFi\",\n",
    "\"Include “Earn crypto with your social networks” in your post\"\n",
    "]\n",
    "missions = [\n",
    "    \"Faire un post pour présenter @product\",\n",
    "    \"Faire une story à propos de @product\",\n",
    "    \"Prendre une photo de vous avec @product\"\n",
    "]\n",
    "# Réponse à vérifier\n",
    "response = \"J'ai acheté @product #SaTT #crypto  hier et je suis très satisfait de mon achat. j'ai partagé une story à propos de mon expérience avec @product.\"\n",
    "\n",
    "# Chargement du modèle de traitement du langage naturel BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        encoded_text = outputs[0][:, 0, :].numpy()\n",
    "    return encoded_text\n",
    "\n",
    "# Expression régulière pour extraire les tags et les mentions\n",
    "pattern = r\"([@#]\\w+)\"\n",
    "# Extraire les tags et les mentions de la réponse\n",
    "response_tags_mentions = set(re.findall(pattern, response))\n",
    "# Extraire le texte de la réponse\n",
    "response_text = re.sub(pattern, \"\", response).strip()\n",
    "# Initialiser le score de validation à 0\n",
    "validation_score = 0\n",
    "total=0\n",
    "# Vérifier chaque mission\n",
    "for mission in missions:\n",
    "    # Extraire les tags et les mentions de la mission\n",
    "    mission_tags_mentions = set(re.findall(pattern, mission))\n",
    "    total+=len(mission_tags_mentions)\n",
    "    # Vérifier si tous les tags et mentions de la mission sont présents dans la réponse\n",
    "    validation_score +=len(mission_tags_mentions.intersection(response_tags_mentions))\n",
    "    mission_text = re.sub(pattern, \"\", mission).strip()\n",
    "    mission_vector = encode_text(mission_text)\n",
    "    response_vector = encode_text(response_text)\n",
    "    # Calculate cosine similarity\n",
    "    similarity = np.dot(mission_vector,  response_vector.T) / (np.linalg.norm(mission_vector) * np.linalg.norm( response_vector.T))\n",
    "    total+=1\n",
    "    if similarity > 0.7:\n",
    "        # Ajouter un point si la similarité est suffisante\n",
    "        validation_score += 1\n",
    "# Afficher le score de validation\n",
    "print(f\"Le score de validation pour la réponse est : {validation_score}/{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Word2Vec\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m word_tokenize\n\u001b[0;32m      7\u001b[0m \u001b[39m# twitter \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# Missions à remplir\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# twitter \n",
    "# Missions à remplir\n",
    "missions = [\n",
    "\"Write a positive sentence about SaTT\",\n",
    "\"Include #SaTT #crypto #influencer #Post2Earn #SocialFi\",\n",
    "\"Include “Earn crypto with your social networks” in your post\"\n",
    "]\n",
    "\n",
    "missions = [\n",
    "    \"Faire un post pour présenter @product\",\n",
    "    \"Faire une story à propos de @product\",\n",
    "    \"Prendre une photo de vous avec @product\"\n",
    "]\n",
    "# Réponse à vérifier\n",
    "response = \"J'ai acheté @product #SaTT #crypto  hier et je suis très satisfait de mon achat. J'ai publié une photo avec @product sur Instagram et j'ai partagé une story à propos de mon expérience avec @product.\"\n",
    "\n",
    "# Chargement du modèle de traitement du langage naturel BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        encoded_text = outputs[0][:, 0, :].numpy()\n",
    "    return encoded_text\n",
    "\n",
    "# Expression régulière pour extraire les tags et les mentions\n",
    "pattern = r\"([@#]\\w+)\"\n",
    "\n",
    "# Extraire les tags et les mentions de la réponse\n",
    "response_tags_mentions = set(re.findall(pattern, response))\n",
    "\n",
    "# Extraire le texte de la réponse\n",
    "response_text = re.sub(pattern, \"\", response).strip()\n",
    "\n",
    "# Initialiser le score de validation à 0\n",
    "validation_score = 0\n",
    "total=0\n",
    "# Vérifier chaque mission\n",
    "for mission in missions:\n",
    "    # Extraire les tags et les mentions de la mission\n",
    "    mission_tags_mentions = set(re.findall(pattern, mission))\n",
    "    total+=len(mission_tags_mentions)\n",
    "    # Vérifier si tous les tags et mentions de la mission sont présents dans la réponse\n",
    "    validation_score +=len(mission_tags_mentions.intersection(response_tags_mentions))\n",
    "    # if mission_tags_mentions and response_tags_mentions.issubset(mission_tags_mentions):\n",
    "    #     print(\"in\")\n",
    "    #     # Ajouter un point si tous les tags et mentions sont présents\n",
    "    #     validation_score += 1\n",
    "    mission_text = re.sub(pattern, \"\", mission).strip()\n",
    "    mission_vector = encode_text(mission_text)\n",
    "    response_vector = encode_text(response_text)\n",
    "    # similarity = np.dot(mission_vector, response_vector.T)\n",
    "    # print(similarity)\n",
    "    # Calculate cosine similarity\n",
    "    similarity = np.dot(mission_vector,  response_vector.T) / (np.linalg.norm(mission_vector) * np.linalg.norm( response_vector.T))\n",
    "    total+=1\n",
    "    print(similarity)\n",
    "    if similarity > 0.7:\n",
    "        # Ajouter un point si la similarité est suffisante\n",
    "        validation_score += 1\n",
    "# Afficher le score de validation\n",
    "print(f\"Le score de validation pour la réponse est : {validation_score}/{total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
